{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char RNN - Prototype\n",
    "\n",
    "to solve the text generation problem as detailed in [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). The objective is to read a large text file, one character at a time, and then be able to generate text (one character at a time) with the same style.\n",
    "\n",
    "We create a notebook to prototype our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data\n",
    "\n",
    "We first download the [The Count of Monte Cristo](https://www.gutenberg.org/ebooks/1184) from Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "PATH_DATA = Path(\"data\")\n",
    "FILENAME_DATA = Path(\"monte_cristo.txt\")\n",
    "URL_DATA = \"https://www.gutenberg.org/files/1184/1184-0.txt\"\n",
    "\n",
    "# Download dataset\n",
    "PATH_DATA.mkdir(exist_ok = True)\n",
    "PATH_DATAFILE = PATH_DATA / FILENAME_DATA\n",
    "if not (PATH_DATAFILE).exists():\n",
    "    r = requests.get(URL_DATA)\n",
    "    PATH_DATAFILE.open(\"wb\").write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the entire text and keep only the interesting lines by removing titles, bibliography…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text:\n",
      "\n",
      "On the 24th of February, 1815, the look-out at Notre-Dame de la Garde\n",
      "signalled the three-master, the Pharaon from Smyrna, Trieste, and\n",
      "Naples.\n",
      "\n",
      "As usual, a pilot put off immediately, and rounding the Château d’If,\n",
      "got on board the vessel between Cape Morgiou and Rion island.\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_DATAFILE, 'r', encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    # Remove start and end of file (not interesting data)\n",
    "    lines = lines[319:60662]\n",
    "    chars = ''.join(lines)\n",
    "            \n",
    "# Test code\n",
    "\n",
    "print(\"Sample text:\\n\")\n",
    "print(chars[:276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chars: 2617219\n",
      "Unique chars: 99\n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "\n",
    "print(\"Total number of chars:\", len(chars))\n",
    "print(\"Unique chars:\", len(set(chars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a dictionary for mapping between chars and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/pytorch/examples/blob/master/word_language_model/data.py\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.char2idx = {}\n",
    "        self.idx2char = []\n",
    "\n",
    "    def add_char(self, char):\n",
    "        if char not in self.char2idx:\n",
    "            self.idx2char.append(char)\n",
    "            self.char2idx[char] = len(self.idx2char) - 1\n",
    "        return self.char2idx[char]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally convert our data from char to token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_dictionary = Dictionary()\n",
    "tensor_data = torch.LongTensor(len(chars))\n",
    "\n",
    "for i, c in enumerate(chars):\n",
    "    tensor_data[i] = data_dictionary.add_char(c)\n",
    "    \n",
    "n_elements = len(data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample values:\n",
      "w (43)\n",
      "  (2)\n",
      "p (35)\n",
      "l (20)\n",
      "a (14)\n",
      "i (30)\n",
      "n (1)\n",
      "l (20)\n",
      "y (15)\n",
      "\n",
      " (28)\n",
      "t (3)\n",
      "h (4)\n",
      "a (14)\n",
      "t (3)\n",
      "  (2)\n",
      "i (30)\n",
      "f (9)\n",
      "  (2)\n",
      "a (14)\n",
      "n (1)\n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "\n",
    "print(\"Sample values:\")\n",
    "print('\\n'.join('{1} ({0})'.format(idx, data_dictionary.idx2char[idx]) for idx in tensor_data[1000:1020]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we split the data between test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = round(0.98 * len(tensor_data))\n",
    "train_data, train_label = tensor_data[:split], tensor_data[1:split+1]\n",
    "valid_data, valid_label = tensor_data[split:-2], tensor_data[split+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a class to handle our training data in batch.\n",
    "\n",
    "We want multiple sequences of text associated to a batch, spread evenly over the text. We create indexes to keep track of the start of each sequence and move them to the next characters at the end of each batch to keep hidden state relevant.\n",
    "\n",
    "![text processing](img/text_processing.png)\n",
    "\n",
    "We also encode the input into one-hot tensors to feed directly into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingData():    \n",
    "    def __init__(self, train_data, train_label, device, sequence_per_batch = 64, char_per_sequence = 128):\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.train_label = train_label\n",
    "        self.sequence_per_batch = sequence_per_batch\n",
    "        self.char_per_sequence = char_per_sequence\n",
    "        self.device = device\n",
    "        self.length = len(train_data)\n",
    "        \n",
    "        # We start reading the text at even sections based on number of sequence per batch\n",
    "        self.batch_idx = range(0, self.length, self.length // sequence_per_batch)\n",
    "        self.batch_idx = self.batch_idx[:sequence_per_batch]\n",
    "        assert len(self.batch_idx) == sequence_per_batch, '{} batches expected vs {} actual'.format(sequence_per_batch,\n",
    "                                                                                                    len(self.batch_idx))\n",
    "        \n",
    "    def next_batch(self):\n",
    "        \n",
    "        # loop to the start if we reached the end of text\n",
    "        self.batch_idx = list(idx if idx + self.char_per_sequence < self.length else 0 for idx in self.batch_idx)\n",
    "        \n",
    "        # Extract sequences\n",
    "        sequences_input = tuple(self.train_data[idx:idx+self.char_per_sequence] for idx in self.batch_idx)\n",
    "        sequences_label = tuple(self.train_label[idx:idx+self.char_per_sequence] for idx in self.batch_idx)\n",
    "\n",
    "        # Transform input into one-hot (source: https://discuss.pytorch.org/t/convert-int-into-one-hot-format/507/29)\n",
    "        sequences_input = tuple(torch.zeros(len(data), n_elements, device = self.device).scatter_(1, data.unsqueeze(-1), 1) for data in sequences_input)\n",
    "        \n",
    "        # Move next idx\n",
    "        self.batch_idx = (idx + self.char_per_sequence for idx in self.batch_idx)\n",
    "        \n",
    "        # Concatenate tensors\n",
    "        return torch.stack(sequences_input, dim=1), torch.stack(sequences_label, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train a neural network\n",
    "\n",
    "We want to create & optimize different variants of following architecture.\n",
    "\n",
    "![architecture](img/architecture.png)\n",
    "\n",
    "We will optimize the RNN module and create our architecture to easily test different variants by choosing:\n",
    "\n",
    "* RNN, LSTM or GRU modules\n",
    "\n",
    "* number of features for hidden states\n",
    "\n",
    "* number of layers\n",
    "\n",
    "* dropout between each layer\n",
    "\n",
    "* batch size (number of sequences processed in parallel during a batch)\n",
    "\n",
    "* input size (number of characters in each sequence)\n",
    "\n",
    "We can decide later to optimize other parameters such as the loss function, optimization algorithm…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, batch_size, rnn_module = \"RNN\", hidden_size = 64, num_layers = 1, dropout = 0):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.rnn_module = rnn_module\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        if rnn_module == \"RNN\":\n",
    "            self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, dropout = dropout)\n",
    "        elif rnn_module == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, dropout = dropout)\n",
    "        elif rnn_module == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, dropout = dropout)\n",
    "            \n",
    "        self.output = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = input.view(1, -1, self.input_size)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.output(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # initialize hidden state to zeros\n",
    "        if self.rnn_module == \"LSTM\":\n",
    "            return torch.zeros(self.num_layers, batch_size, self.hidden_size), torch.zeros(\n",
    "                self.num_layers, batch_size, self.hidden_size)\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define a loss and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer_function = optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7b5bf39af04b76804c5d6338406d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a27a9a480614e088ac8704f312b3230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss 3.1059245330810548 - Validation loss 2.695492514909661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac49d66f235479f81b033ace444fdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training loss 2.419619833374021 - Validation loss 2.2780075974377856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f680e44f5b64d87b6e1c37c428ad9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training loss 2.1597442972819016 - Validation loss 2.103667762217982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cfbd821aec4b0b8310133fe53c15b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training loss 2.0155672790527355 - Validation loss 1.9676023394069149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b78eee96c744452b6c408e45d1ef3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training loss 1.9313430516560879 - Validation loss 1.8954456084226652\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc25f8c30d9840a0b0065d8975623981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training loss 1.83999774424235 - Validation loss 1.8342455381676595\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b3c52565c5485a82bfed30d41e1744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training loss 1.8135996297200543 - Validation loss 1.7796529887437211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85edaeb29cc34655b9986281b49a8e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training loss 1.7714799194335928 - Validation loss 1.744904908431321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d143b103296d47afa25ff728173fbd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training loss 1.7085739954630548 - Validation loss 1.7063948945278975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152c6cd78d104217aba0393af2c5bb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training loss 1.670262375386555 - Validation loss 1.6800991733761785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c74d9d66754b029aaab0e038e5b431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training loss 1.647395095825195 - Validation loss 1.6589835505685004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7fa6a128cf4176be1352dae69518dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training loss 1.645564945475261 - Validation loss 1.6323724012539989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8db00461417408b9dde2abd7bdcb4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training loss 1.59362932993571 - Validation loss 1.6044038320735028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baea52eedd1e4cb3a6a003025496e225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training loss 1.5748805206298835 - Validation loss 1.5948034398764097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b328194e15d45d392c2ffbd881474be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training loss 1.578380380249023 - Validation loss 1.5785795410102816\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f232c0557af456b9059c55d9abdb23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training loss 1.5697588765462236 - Validation loss 1.5620818521707618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81edac0d7c242c2bc0dae957816abee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training loss 1.5202949132283532 - Validation loss 1.5340196983662115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a498075e5d4f435abfa13ff112d70063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training loss 1.517479506683349 - Validation loss 1.526218808117962\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e972dbf7a68c42d6b48f7c4c04c07971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training loss 1.5296867800394687 - Validation loss 1.5256320089366522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a911264a2514dd9992f00b56b55778b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training loss 1.5292602198282876 - Validation loss 1.5057634775868523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tnrange\n",
    "from numpy import random\n",
    "\n",
    "# Define hyper-parameters\n",
    "rnn_module = \"GRU\"\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "epochs = 20\n",
    "batches_per_epoch = 300\n",
    "sequence_per_batch = 8\n",
    "char_per_sequence = 50\n",
    "\n",
    "# Build the NN\n",
    "model = Model(len(data_dictionary), sequence_per_batch, rnn_module, hidden_size, num_layers, dropout)\n",
    "hidden = model.initHidden(sequence_per_batch)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = train_data.to(device)\n",
    "train_label = train_label.to(device)\n",
    "valid_data = valid_data.to(device)\n",
    "valid_label = valid_label.to(device)\n",
    "model.to(device)\n",
    "if rnn_module == \"LSTM\":\n",
    "    for h in hidden:\n",
    "        h = h.to(device)\n",
    "else:\n",
    "    hidden = hidden.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optimizer_function(model.parameters())\n",
    "\n",
    "# Load data\n",
    "training_data = TrainingData(train_data, train_label, device, sequence_per_batch, char_per_sequence)\n",
    "valid_length = len(valid_data)\n",
    "\n",
    "for epoch in tnrange(epochs):\n",
    "    train_loss = 0   # training loss\n",
    "    valid_loss = 0   # validation loss\n",
    "    \n",
    "    # Training of one epoch\n",
    "    model.train()\n",
    "    for i in tnrange(batches_per_epoch):\n",
    "        \n",
    "        # Get a batch of sequences\n",
    "        input_vals, label_vals = training_data.next_batch()\n",
    "\n",
    "        # Detach hidden layer and reset gradients\n",
    "        if rnn_module == \"LSTM\":\n",
    "            tuple(h.detach_() for h in hidden)\n",
    "        else:\n",
    "            hidden.detach_()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass and calculate loss\n",
    "        loss_sequence = torch.zeros(1, device=device)\n",
    "        for (input_val, label_val) in zip(input_vals, label_vals):\n",
    "            output, hidden = model(input_val, hidden)\n",
    "            loss = loss_function(output, label_val.view(-1))\n",
    "            loss_sequence += loss\n",
    "            \n",
    "        # Backward propagation and weight update\n",
    "        loss_sequence.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss_sequence.item() / batches_per_epoch / char_per_sequence\n",
    "        \n",
    "    # Calculate validation loss\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        # Detach hidden layers\n",
    "        hidden_valid = model.initHidden(1)\n",
    "        if rnn_module == \"LSTM\":\n",
    "            for h in hidden_valid:\n",
    "                h = h.to(device)\n",
    "        else:\n",
    "            hidden_valid = hidden_valid.to(device)\n",
    "            \n",
    "        # Process validation data one character at a time\n",
    "        for i in range(valid_length-1):\n",
    "            input_val = valid_data[i].view(1)\n",
    "            label_val = valid_label[i]\n",
    "\n",
    "            # One-hot input\n",
    "            input_val = torch.zeros(len(input_val), n_elements, device = device).scatter_(1, input_val.unsqueeze(-1), 1)\n",
    "\n",
    "            # Forward pass and calculate loss\n",
    "            output, hidden_valid = model(input_val, hidden_valid)\n",
    "            loss = loss_function(output, label_val.view(-1))\n",
    "            valid_loss += loss.item() / (valid_length - 1)\n",
    "        \n",
    "    print(\"Epoch {} - Training loss {} - Validation loss {}\".format(epoch+1, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure to save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/.local/share/virtualenvs/char-RNN-1RHRW0ft/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "PATH_MODEL = \"model.pt\"\n",
    "torch.save(model, PATH_MODEL)\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "We finally test the model by predicting a few characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load model\n",
    "PATH_MODEL = \"model.pt\"\n",
    "model = torch.load(PATH_MODEL)\n",
    "\n",
    "# Move model to CPU\n",
    "model = model.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing sequence: The \n",
      "Predicted sequence:\n",
      " The dear was heard on a man.\n",
      "\n",
      "“The would did not now he wish rement the grave of the young man with the last of the Paris, and her\n",
      "carry so a son of the door.\n",
      "\n",
      "“I do you will be four a moment to the prove you will a corntion, and where the doung the still of the sconvers\n",
      "of the miscondens. I will to de Valentine, and the discontort of the count of the tell me to him.\n",
      "\n",
      "“The young man he was a mistors, and with the moment.”\n",
      "\n",
      "“Yes; the house, a fortune of the door would but with the young say with\n",
      "make on they sign to him to be some the shall be a\n",
      "stand, and I am some contrace, and the dear in the abbé with my\n",
      "father he had to say at the count of the count of the stranger to\n",
      "his whore to preserte to live to dear and with the stranger\n",
      "of the minise of the world to be a mistone was so like which could be\n",
      "a valling of the still signate and known.\n",
      "\n",
      "“But the same of the same of a man.”\n",
      "\n",
      "“Yes, my did not see of which the years of the dong the same of the partract of yourself, and who had\n",
      "been that \n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Go into evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Define a sequence of characters to initialize the hidden states\n",
    "    init_chars = \"The \"\n",
    "\n",
    "    init_data = torch.LongTensor(len(init_chars))\n",
    "    for i, c in enumerate(init_chars):\n",
    "        init_data[i] = data_dictionary.char2idx[c]\n",
    "\n",
    "    # Transform into one-hot\n",
    "    init_data = torch.zeros(len(init_data), len(data_dictionary)).scatter_(1, init_data.unsqueeze(-1), 1)\n",
    "\n",
    "    # Initialize hidden layer and feed sequence of characters to the model\n",
    "    hidden = model.initHidden(1)\n",
    "    for init_char in init_data:\n",
    "        output, hidden = model(init_char, hidden)\n",
    "\n",
    "    # Predict next characters one at a time\n",
    "    number_chars = 1000\n",
    "    chars = init_chars\n",
    "    for _ in range(number_chars):\n",
    "\n",
    "        # Calculate probability distribution of outputs with a temperature of 0.5\n",
    "        prob = nn.Softmax(1)(output/0.5).squeeze().numpy()\n",
    "\n",
    "        # Sample from outputs\n",
    "        output_idx = random.choice(len(prob), p = prob)\n",
    "\n",
    "        # Extract predicted char\n",
    "        predicted_char = data_dictionary.idx2char[output_idx]\n",
    "        chars += predicted_char\n",
    "\n",
    "        # Transform predicted char into one-hot vector\n",
    "        output_idx = torch.LongTensor([[output_idx]])\n",
    "        next_input = torch.zeros(len(output_idx), len(data_dictionary)).scatter_(1, output_idx, 1)\n",
    "\n",
    "        # Feed into NN to predict next char\n",
    "        output, hidden = model(next_input, hidden)\n",
    "\n",
    "    # Print predicted sequence\n",
    "    print(\"Initializing sequence:\", init_chars)\n",
    "    print(\"Predicted sequence:\\n\", chars)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so bad for only 10mn of training, or actually **only 5mn of training** (+ 5mn of validation) !\n",
    "\n",
    "I'm sure we can do better though !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "At this point we would want to fine-tune our neural network for better results.\n",
    "\n",
    "We now have completed our prototype and it is time to move our code to a separate Python file (or multiple for organized people). This will help in cleaning our code and running easily multiple experiments at the same time (locally or remotely).\n",
    "\n",
    "We will monitor our experiments through [Weights & Biases](https://www.wandb.com/) so that we can easily analyze and compare the results while keeping track of the code and model associated to each run.\n",
    "\n",
    "Refer to [the project README](https://github.com/borisd13/char-RNN/blob/master/README.md) for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
