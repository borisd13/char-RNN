{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char RNN - Prototype\n",
    "\n",
    "The main objective of this project is to set up a workflow for defining, training and optimizing neural networks.\n",
    "\n",
    "We are going to predict next characters from sample text, similar to [char-rnn](https://github.com/karpathy/char-rnn).\n",
    "\n",
    "We create a notebook which will serve as prototyping our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data\n",
    "\n",
    "We first download the [The Count of Monte Cristo](https://www.gutenberg.org/ebooks/1184) from Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "PATH_DATA = Path(\"data\")\n",
    "FILENAME_DATA = Path(\"monte_cristo.txt\")\n",
    "URL_DATA = \"https://www.gutenberg.org/files/1184/1184-0.txt\"\n",
    "\n",
    "# Download dataset\n",
    "PATH_DATA.mkdir(exist_ok = True)\n",
    "PATH_DATAFILE = PATH_DATA / FILENAME_DATA\n",
    "if not (PATH_DATAFILE).exists():\n",
    "    r = requests.get(URL_DATA)\n",
    "    PATH_DATAFILE.open(\"wb\").write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the entire text and keep only the interesting lines by removing titles, bibliography…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text:\n",
      "\n",
      "On the 24th of February, 1815, the look-out at Notre-Dame de la Garde\n",
      "signalled the three-master, the Pharaon from Smyrna, Trieste, and\n",
      "Naples.\n",
      "\n",
      "As usual, a pilot put off immediately, and rounding the Château d’If,\n",
      "got on board the vessel between Cape Morgiou and Rion island.\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_DATAFILE, 'r', encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    # Remove start and end of file (not interesting data)\n",
    "    lines = lines[319:60662]\n",
    "    chars = ''.join(lines)\n",
    "            \n",
    "# Test code\n",
    "\n",
    "print(\"Sample text:\\n\")\n",
    "print(chars[:276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chars: 2617219\n",
      "Unique chars: 99\n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "\n",
    "print(\"Total number of chars:\", len(chars))\n",
    "print(\"Unique chars:\", len(set(chars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a dictionary for mapping between chars and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/pytorch/examples/blob/master/word_language_model/data.py\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.char2idx = {}\n",
    "        self.idx2char = []\n",
    "\n",
    "    def add_char(self, char):\n",
    "        if char not in self.char2idx:\n",
    "            self.idx2char.append(char)\n",
    "            self.char2idx[char] = len(self.idx2char) - 1\n",
    "        return self.char2idx[char]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally convert our data from char to token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_dictionary = Dictionary()\n",
    "tensor_data = torch.LongTensor(len(chars))\n",
    "\n",
    "for i, c in enumerate(chars):\n",
    "    tensor_data[i] = data_dictionary.add_char(c)\n",
    "    \n",
    "n_elements = len(data_dictionary)\n",
    "    \n",
    "# Transform into one-hot (source: https://discuss.pytorch.org/t/convert-int-into-one-hot-format/507/29)\n",
    "input_data = torch.zeros(len(tensor_data), n_elements).scatter_(1, tensor_data.unsqueeze(-1), 1)\n",
    "label_data = tensor_data  # we don't need labels in one-hot format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample values:\n",
      "i (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n",
      "g (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n",
      "g (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n",
      "e (tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n",
      "d (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "\n",
    "print(\"Sample values:\")\n",
    "print('\\n'.join('{1} ({0})'.format(idx, data_dictionary.idx2char[idx.argmax()]) for idx in input_data[506:511]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we split the data between test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = round(0.95 * len(tensor_data))\n",
    "train_data, train_label = input_data[:split], label_data[1:split+1]\n",
    "valid_data, valid_label = input_data[split:-2], label_data[split+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a class to handle our training data in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingData():\n",
    "    \n",
    "    def __init__(self, train_data, train_label, sequence_per_batch = 64, char_per_sequence = 128):\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.train_label = train_label\n",
    "        self.sequence_per_batch = sequence_per_batch\n",
    "        self.char_per_sequence = char_per_sequence\n",
    "        self.length = len(train_data)\n",
    "        \n",
    "        # We start reading the text at even sections based on number of sequence per batch\n",
    "        self.batch_idx = range(0, self.length, self.length // sequence_per_batch)\n",
    "        self.batch_idx = self.batch_idx[:sequence_per_batch]\n",
    "        assert len(self.batch_idx) == sequence_per_batch, '{} batches expected vs {} actual'.format(sequence_per_batch,\n",
    "                                                                                                    len(self.batch_idx))\n",
    "        \n",
    "    def next_batch(self):\n",
    "        \n",
    "        # loop to the start if we reached the end of text\n",
    "        self.batch_idx = list(idx if idx + self.char_per_sequence < self.length else 0 for idx in self.batch_idx)\n",
    "        \n",
    "        # Extract sequences\n",
    "        sequences_input = tuple(self.train_data[idx:idx+self.char_per_sequence] for idx in self.batch_idx)\n",
    "        sequences_label = tuple(self.train_label[idx:idx+self.char_per_sequence] for idx in self.batch_idx)\n",
    "        \n",
    "        # Move next idx\n",
    "        self.batch_idx = (idx + self.char_per_sequence for idx in self.batch_idx)\n",
    "        \n",
    "        # Concatenate tensors\n",
    "        return torch.stack(sequences_input, dim=1), torch.stack(sequences_label, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train a neural network\n",
    "\n",
    "We will create & optimize different variants of following architecture.\n",
    "\n",
    "![architecture](img/architecture.png)\n",
    "\n",
    "We want to optimize the RNN module and will create our architecture so we can easily test different variants by choosing:\n",
    "\n",
    "* RNN, LSTM or GRU modules\n",
    "\n",
    "* number of features for hidden states\n",
    "\n",
    "* number of layers\n",
    "\n",
    "* dropout between each layer\n",
    "\n",
    "We can decide to optimize other parameters such as the loss function, optimization algorithm…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, batch_size, rnn_module = \"RNN\", hidden_size = 64, num_layers = 1, dropout = 0):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.rnn_module = rnn_module\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        if rnn_module == \"RNN\":\n",
    "            self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, dropout = dropout)\n",
    "        elif rnn_module == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, dropout = dropout)\n",
    "        elif rnn_module == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, dropout = dropout)\n",
    "            \n",
    "        self.output = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = input.view(1, -1, self.input_size)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.output(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # initialize hidden state with a sequence of word tokens\n",
    "        if self.rnn_module == \"LSTM\":\n",
    "            return torch.zeros(self.num_layers, batch_size, self.hidden_size), torch.zeros(\n",
    "                self.num_layers, batch_size, self.hidden_size)\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define a loss and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer_function = optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b235c840618e41da8b7bf42bccd2dea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a7005f77224a338a271da4a9d7941f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss 3.1934996656629773 - Validation loss 3.144932621842185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8c3056be41497cb08b6369e0ad26d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training loss 2.8241447692871127 - Validation loss 2.4369557873105694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c4837ccb8649a4b886b02139beb210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training loss 2.219004919433594 - Validation loss 2.0687018499885386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7e6152cff1419f876a787a9e104b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training loss 1.979423703342013 - Validation loss 1.8893669783129634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a244f8e144804e10b38ce285ef925297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training loss 1.8262373640272354 - Validation loss 1.7676303601661845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e628d550e434b1bbdfffdc8c7d7c5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training loss 1.7440616529676654 - Validation loss 1.6796516327052655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722b8350165a4703895b27cf4a05102b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training loss 1.6771019402398006 - Validation loss 1.617867936727862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fbde2f4eb14f39b68c65d648314447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training loss 1.6414653625488282 - Validation loss 1.580928250283886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d760958626ce4aca9846c76bc12f9764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training loss 1.6024891991509325 - Validation loss 1.5495697640584145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb84b8b2220544b2bef5e7b3900b5d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training loss 1.5644219733344191 - Validation loss 1.517771163837093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7357831fdfd54c60bea52f916d064203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training loss 1.5249412611219633 - Validation loss 1.49103122921999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7b3010a56b426097c65cbbb445b68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training loss 1.476718608940971 - Validation loss 1.467593610196495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573552a34fa04e85ab4979e8aa0de411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training loss 1.488179114108616 - Validation loss 1.4426441057710506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb201cfd7aa4c7e82f17a5443652ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training loss 1.4606490607367626 - Validation loss 1.4251791901414947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbff5e562bc498ebff50d32b69eb7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training loss 1.4658463846842447 - Validation loss 1.4124646140532293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89fb73c83d841f4ac72e6c699111c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training loss 1.4516935129801423 - Validation loss 1.402943426306773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b50c7e94c374be7bb150426fb0922e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training loss 1.4215876363118485 - Validation loss 1.3884444893026875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4e6c7e87be4a689e3b620f24ab734b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training loss 1.4112147203233505 - Validation loss 1.383614418471269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09d07ec05844d588c6d50655d0f43be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training loss 1.3705495961507166 - Validation loss 1.3699844603245122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbfd71d340e432091b7c4d417bc184b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training loss 1.3904286878797738 - Validation loss 1.3515454359360024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de44a6e2a7e4c12a3a9cab126ceefce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training loss 1.3808272043863943 - Validation loss 1.3518721754932794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b9b46de16e414aae75d11d6cfa4ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Training loss 1.4023079586452905 - Validation loss 1.3543114321080731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d949fb8a08a941c2ab5ff2a9aefe2a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Training loss 1.3781555331759994 - Validation loss 1.3424739416736393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f1cbae5da64a3bb42198770727fd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Training loss 1.358474062093099 - Validation loss 1.330604566974843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c5a998d96f46a88ee8a4d53568962b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Training loss 1.3532692342122405 - Validation loss 1.3349498071905073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2151add724e8450e85b994f516f7402b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Training loss 1.3221237708197697 - Validation loss 1.328996052717084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae3cb5162194533a66e93f8dbe2baf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Training loss 1.3399309380425355 - Validation loss 1.3089096201311796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdcdff5e2bb4a55b523a3559cc3dd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Training loss 1.3383069573296447 - Validation loss 1.310190858221341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d1fb3992344edcb553577cb3a3d4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Training loss 1.3629359188503698 - Validation loss 1.3080112175446816\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72d750978bf43a9ac0a2f6c928d870d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Training loss 1.3396507527669272 - Validation loss 1.3078746282498113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6026ae0471a4b309a0ad080639b8770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Training loss 1.3195872148301877 - Validation loss 1.296608580798723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a837ef0c5d2b4ea8adc4c164076f1e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Training loss 1.3151345499674465 - Validation loss 1.2977992571244428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5611dad72944a29ef1106d54bf71cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tnrange\n",
    "from numpy import random\n",
    "\n",
    "# Define hyper-parameters\n",
    "rnn_module = \"GRU\"\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "dropout = 0.1\n",
    "epochs = 100\n",
    "batches_per_epoch = 300\n",
    "sequence_per_batch = 8\n",
    "char_per_sequence = 150\n",
    "\n",
    "# Build the NN\n",
    "model = Model(len(data_dictionary), sequence_per_batch, rnn_module, hidden_size, num_layers, dropout)\n",
    "hidden = model.initHidden(sequence_per_batch)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")   # for some reason, it goes much faster in my experiments\n",
    "train_data = train_data.to(device)\n",
    "train_label = train_label.to(device)\n",
    "valid_data = valid_data.to(device)\n",
    "valid_label = valid_label.to(device)\n",
    "model.to(device)\n",
    "hidden = hidden.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optimizer_function(model.parameters())\n",
    "\n",
    "# Load data\n",
    "training_data = TrainingData(train_data, train_label, sequence_per_batch, char_per_sequence)\n",
    "\n",
    "valid_length = len(valid_data)\n",
    "\n",
    "for epoch in tnrange(epochs):\n",
    "    train_loss = 0   # training loss\n",
    "    valid_loss = 0   # validation loss\n",
    "    \n",
    "    # Training of one epoch\n",
    "    model.train()\n",
    "    for i in tnrange(batches_per_epoch):\n",
    "        \n",
    "        # Get a batch of sequences\n",
    "        input_vals, label_vals = training_data.next_batch()\n",
    "\n",
    "        # Detach hidden layer and reset gradients\n",
    "        if rnn_module == \"LSTM\":\n",
    "            tuple(h.detach_() for h in hidden)\n",
    "        else:\n",
    "            hidden.detach_()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass and calculate loss\n",
    "        loss_sequence = torch.zeros(1, device=device)\n",
    "        for (input_val, label_val) in zip(input_vals, label_vals):\n",
    "            output, hidden = model(input_val, hidden)\n",
    "            loss = loss_function(output, label_val.view(-1))\n",
    "            loss_sequence += loss\n",
    "            \n",
    "        # Backward propagation and weight update\n",
    "        loss_sequence.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss_sequence.item() / batches_per_epoch / char_per_sequence\n",
    "        \n",
    "    # Calculate validation loss\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        hidden_valid = model.initHidden(1).to(device)\n",
    "        for i in range(valid_length-1):\n",
    "            input_val = valid_data[i]\n",
    "            label_val = valid_label[i].view(1)\n",
    "            output, hidden_valid = model(input_val, hidden_valid)\n",
    "            loss = loss_function(output, label_val)\n",
    "            valid_loss += loss.item() / (valid_length - 1)\n",
    "        \n",
    "    print(\"Epoch {} - Training loss {} - Validation loss {}\".format(epoch+1, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure to save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "PATH_MODEL = \"model.pt\"\n",
    "torch.save(model, PATH_MODEL)\n",
    "\n",
    "# Load model\n",
    "model = torch.load(PATH_MODEL)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "We finally test the model by predicting a few characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Define a sequence of characters to initialize the hidden states\n",
    "    init_chars = \"The \"\n",
    "\n",
    "    init_data = torch.LongTensor(len(init_chars))\n",
    "    for i, c in enumerate(init_chars):\n",
    "        init_data[i] = data_dictionary.char2idx[c]\n",
    "\n",
    "    # Transform into one-hot\n",
    "    init_data = torch.zeros(len(init_data), len(data_dictionary)).scatter_(1, init_data.unsqueeze(-1), 1)\n",
    "\n",
    "    # Initialize hidden layer and feed sequence of characters to the model\n",
    "    hidden = model.initHidden(1)\n",
    "    for init_char in init_data:\n",
    "        output, hidden = model(init_char, hidden)\n",
    "\n",
    "    # Predict next characters one at a time\n",
    "    number_chars = 500\n",
    "    chars = init_chars\n",
    "    for _ in range(number_chars):\n",
    "\n",
    "        # Calculate probability distribution of outputs with a temperature of 0.5\n",
    "        prob = nn.Softmax(1)(output/0.5).squeeze().numpy()\n",
    "\n",
    "        # Sample from outputs\n",
    "        output_idx = random.choice(len(prob), p = prob)\n",
    "\n",
    "        # Extract predicted char\n",
    "        predicted_char = data_dictionary.idx2char[output_idx]\n",
    "        chars += predicted_char\n",
    "\n",
    "        # Transform predicted char into one-hot vector\n",
    "        output_idx = torch.LongTensor([[output_idx]])\n",
    "        next_input = torch.zeros(len(output_idx), len(data_dictionary)).scatter_(1, output_idx, 1)\n",
    "\n",
    "        # Feed into NN to predict next char\n",
    "        output, hidden = model(next_input, hidden)\n",
    "\n",
    "    # Print predicted sequence\n",
    "    print(\"Initializing sequence:\", init_chars)\n",
    "    print(\"Predicted sequence:\", chars)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems to be working and we now want to do some optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "At this point we would want to fine-tune by implementing:\n",
    "\n",
    "* monitoring features (plot graph in real time)\n",
    "\n",
    "* comparison of past experiments\n",
    "\n",
    "However we would be wasting our time. [Weights & Biases](https://www.wandb.com/) will do that for us quicker and will provide additional insight tools.\n",
    "\n",
    "We have now completed our prototype and it is time to move our code to a separate Python file (or multiple for organized people). This will help in cleaning our code and running multiple experiments at the same time (locally or remotely).\n",
    "\n",
    "Refer to my tutorial for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
